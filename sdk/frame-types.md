---
description: >-
  NDI sending and receiving use common structures to define video, audio, and
  metadata types. The parameters of these structures are documented below.
---

# Frame Types

### Video Frames (NDILIB\_VIDEO\_FRAME\_V2\_T)

<table data-full-width="true"><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td><strong>xres, yres (int)</strong></td><td>This is the resolution of the frame expressed in pixels. Note that, because data is internally all considered in 4:2:2 formats, image width values should be divisible by two.</td></tr><tr><td><p><strong>FourCC</strong> </p><p><strong>(NDIlib_FourCC_video_type_e)</strong></p></td><td>This is the pixel format for this buffer. <strong>The supported formats are listed in the table below</strong>.</td></tr></tbody></table>

<table data-full-width="false"><thead><tr><th width="274">FourCC</th><th>Description</th></tr></thead><tbody><tr><td></td><td></td></tr><tr><td><strong>NDIlib_FourCC_type_UYVY</strong></td><td><p>This is a buffer in the “UYVY” FourCC and represents a 4:2:2 image in YUV color space. There is a Y sample at every pixel, and U and V sampled at every second pixel horizontally on each line. A macro-pixel contains 2 pixels in 1 DWORD. The ordering of these pixels is U0, Y0, V0, Y1.</p><p></p><p>Please see the notes below regarding the expected YUV color space for different resolutions.</p><p></p><p>Note that when using UYVY video, the color space is maintained end-to-end through the pipeline, which is consistent with how almost all video is created and displayed.</p></td></tr><tr><td><strong>NDIlib_FourCC_type_UYVA</strong></td><td><p>This is a buffer that represents a 4:2:2:4 image in YUV color space. There is a Y sample at every pixels with U,V sampled at every second pixel horizontally. There are two planes in memory, the first being the UYVY color plane, and the second the alpha plane that immediately follows the first.</p><p></p><p>For instance, if you have an image with <code>p_data</code> and <code>stride</code>, then the planes are located as follows:</p><pre><code>    uint8_t *p_uyvy = (uint8_t*)p_data; 
    uint8_t *p_alpha = p_uyvy + stride*yres;
</code></pre></td></tr><tr><td><strong>NDIlib_FourCC_type_P216</strong></td><td><p>This is a 4:2:2 buffer in semi-planar format with full 16bpp color precision. This is formed from two buffers in memory, the first is a 16bpp luminance buffer and the second is a buffer of U,V pairs in memory. This can be considered as a 16bpp version of NV12.</p><p></p><p>For instance, if you have an image with <code>p_data</code> and <code>stride</code>, then the planes are located as follows:</p><pre class="language-json"><code class="lang-json">    uint16_t *p_y = (uint16_t*)p_data;
    uint16_t *p_uv = (uint16_t*)(p_data + stride*yres);
</code></pre><p>As a matter of illustration, a completely packed image would have stride as <code>xres*sizeof(uint16_t)</code>.</p></td></tr><tr><td><strong>NDIlib_FourCC_type_PA16</strong></td><td><p>This is a 4:2:2:4 buffer in semi-planar format with full 16bpp color and alpha precision. This is formed from three buffers in memory. The first is a 16bpp luminance buffer, and the second is a buffer of U,V pairs in memory. A single plane alpha channel at 16bpp follows the U,V pairs.</p><p></p><p>For instance, if you have an image with p_data and stride, then the planes are located as follows:</p><pre class="language-json"><code class="lang-json">    uint16_t *p_y = (uint16_t*)p_data; 
    uint16_t *p_uv = p_y + stride*yres; 
    uint16_t *p_alpha = p_uv + stride*yres;
</code></pre><p>To illustrate, a completely packed image would have stride as</p><p><code>xres*sizeof(uint16_t)</code>.</p></td></tr><tr><td><strong>NDIlib_FourCC_type_YV12</strong></td><td><p>This is a planar 4:2:0 in Y, U, V planes in memory.</p><p></p><p>For instance, if you have an image with p_data and stride, then the planes are located as follows:</p><pre class="language-json"><code class="lang-json">    uint8_t *p_y = (uint8_t*)p_data;
    uint8_t *p_v = p_y + stride*yres; 
    uint8_t *p_u = p_v + (stride/2)*(yres/2);
</code></pre><p>As a matter of illustration, a completely packed image would have stride as <code>xres*sizeof(uint8_t)</code>.</p></td></tr><tr><td><strong>NDIlib_FourCC_type_I420</strong></td><td><p>This is a planar 4:2:0 in Y,U,V planes in memory with the U,V planes reversed from the YV12 format.</p><p></p><p>For instance, if you have an image with p_data and stride, then the planes are located as follows:</p><pre class="language-json"><code class="lang-json">    uint8_t *p_y = (uint8_t*)p_data;
    uint8_t *p_v = p_y + stride*yres; 
    uint8_t *p_u = p_v + (stride/2)*(yres/2);
</code></pre><p>To illustrate, a completely packed image would have stride as</p><p><code>xres*sizeof(uint8_t)</code>.</p></td></tr><tr><td><strong>NDIlib_FourCC_type_NV12</strong></td><td><p>This is a semi planar 4:2:0 in Y, UV planes in memory. The luminance plane is at the lowest memory address with the UV pairs immediately following them.</p><p>For instance, if you have an image with p_data and stride, then the planes are located as follows:</p><pre class="language-json"><code class="lang-json">      uint8_t *p_y = (uint8_t*)p_data;
      uint8_t *p_uv = p_y + stride*yres;
</code></pre><p>To illustrate, a completely packed image would have stride as</p><p>xres*sizeof(uint8_t).</p></td></tr><tr><td><strong>NDIlib_FourCC_type_BGRA</strong></td><td>A 4:4:4:4, 8-bit image of red, green, blue and alpha components, in memory order blue, green, red, alpha. This data is not pre-multiplied.</td></tr><tr><td><strong>NDIlib_FourCC_type_BGRX</strong></td><td><p>A 4:4:4, 8-bit image of red, green, blue components, in memory order blue, green, red, 255. This data is not pre-multiplied.</p><p>This is identical to BGRA, but is provided as a hint that all alpha channel values are 255, meaning that alpha compositing may be avoided. The lack of an alpha channel is used by the SDK to improve performance when possible.</p></td></tr><tr><td><strong>NDIlib_FourCC_type_RGBA</strong></td><td>A 4:4:4:4, 8-bit image of red, green, blue and alpha components, in memory order red, green, blue, alpha. This data is not pre-multiplied.</td></tr><tr><td><strong>NDIlib_FourCC_type_RGBX</strong></td><td><p>A 4:4:4, 8-bit image of red, green, blue components, in memory order red, green, blue, 255. This data is not pre-multiplied.</p><p>This is identical to RGBA, but is provided as a hint that all alpha channel values are 255, meaning that alpha compositing may be avoided. The lack of an alpha channel is used by the SDK to improve performance when possible.</p></td></tr></tbody></table>

When running in a YUV color space, the following standards are applied:

<table data-full-width="false"><thead><tr><th width="379">Resolution</th><th>Standard</th></tr></thead><tbody><tr><td><strong>SD resolutions</strong></td><td>BT.601</td></tr><tr><td><p><strong>HD resolutions</strong> </p><p><strong><code>xres>720 || yres>576</code></strong></p></td><td>Rec.709 </td></tr><tr><td><strong>UHD resolutions</strong><br><strong><code>xres>1920 || yres>1080</code></strong></td><td>Rec.2020</td></tr><tr><td><strong>Alpha channel</strong></td><td>Full range for data type <br>(0-255 range when running 8-bit and 0-65536 range when running 16-bit.)</td></tr></tbody></table>

For the sake of compatibility with standard system components, Windows APIs expose 8-bit UYVY and RGBA video (common FourCCs used in all media applications).

<table data-full-width="true"><thead><tr><th>Parameters (Continued)</th><th></th></tr></thead><tbody><tr><td></td><td>Description</td></tr><tr><td>frame_rate_N, frame_rate_D (int)</td><td><p>This is the framerate of the current frame. The framerate is specified as a numerator and denominator, such that the following is valid:</p><p>frame_rate = (float)frame_rate_N / (float)frame_rate_D</p><p>Some examples of common framerates are presented in the table below.</p></td></tr></tbody></table>
